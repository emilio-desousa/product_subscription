{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gridsearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import product_sub.settings as stg\n",
    "from product_sub.infrastructure.eco_social import EcoSocioContext\n",
    "from product_sub.infrastructure.bank_campaign import MarketingCampaign\n",
    "from product_sub.infrastructure.dataset_builder import DatasetBuilder\n",
    "from product_sub.domain.data_cleaning import CatImputer, NumImputer\n",
    "from product_sub.domain.feature_creator import CategoricalCreatorFromNumerical, CategoricalFeatureCreator\n",
    "from product_sub.domain.feature_encoder import FrequencyEncoder, OneHotEncoder\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.compose import make_column_selector as selector\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.pipeline import FeatureUnion, Pipeline, make_pipeline, make_union\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construction pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_merged = DatasetBuilder(\"data.csv\", \"socio_eco.csv\").create_dataset()\n",
    "RANDOM_STATE = 89\n",
    "cv = StratifiedKFold(shuffle=True, n_splits=5, random_state=RANDOM_STATE)\n",
    "\n",
    "X = dataset_merged.drop(columns=stg.COL_RAW_SUBSCRIPTION)\n",
    "y = dataset_merged[stg.COL_RAW_SUBSCRIPTION].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RANDOM_STATE)\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[(\"num_imputer\", NumImputer()),\n",
    "                                      (\"create_categorical\",CategoricalCreatorFromNumerical(stg.DICT_TO_CREATE_COLS)),\n",
    "                                      (\"scaler\", MinMaxScaler())])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[(\"cat_imputer\", CatImputer()),\n",
    "                                          (\"cat_creator\", CategoricalFeatureCreator()),\n",
    "                                          (\"freq_encoder\", FrequencyEncoder(stg.COLS_TO_FREQ_ENCODE)),\n",
    "                                          (\"one_hot_encoder\", OneHotEncoder([stg.COL_RAW_JOB]))])\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=[(\"num\", numeric_transformer, selector(dtype_exclude=\"category\")),\n",
    "                                               (\"cat\", categorical_transformer, selector(dtype_include=\"category\"))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = Pipeline(steps=[('preprocessor' , preprocessor),\n",
    "                      ('lr',  LogisticRegression())])\n",
    "\n",
    "#lr.get_params().keys()\n",
    "#search.best_params_\n",
    "\n",
    "params_grid_lr = {'lr' : [LogisticRegression()],\n",
    "                  'lr__penalty' : ['l1'],\n",
    "                  'lr__C' : [2.6366],\n",
    "                  'lr__solver' : ['saga']}\n",
    "\n",
    "search = GridSearchCV(lr, params_grid_lr, n_jobs=-1, cv=cv, verbose=0, scoring='accuracy')\n",
    "\n",
    "search.fit(X_train, y_train)\n",
    "\n",
    "y_pred = search.predict(X_test)\n",
    "\n",
    "print(f'\\nLe meilleur score entraînement est : {search.best_score_}\\n') # 0.9067\n",
    "print(f'\\nLe meilleur score test est : {search.score(X_test, y_test)}') # 0.9038"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.92      0.98      0.95      7636\n",
      "         Yes       0.67      0.37      0.48      1030\n",
      "\n",
      "    accuracy                           0.90      8666\n",
      "   macro avg       0.80      0.67      0.71      8666\n",
      "weighted avg       0.89      0.90      0.89      8666\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true=y_test, y_pred=y_pred, target_names = ['No','Yes']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = Pipeline(steps=[('preprocessor' , preprocessor),\n",
    "                      ('svm', SVC())])\n",
    "\n",
    "#svc.get_params().keys()\n",
    "#search.best_params_\n",
    "\n",
    "params_grid_svc = {'svm' : [SVC()],\n",
    "                   'svm__C' : [100],\n",
    "                   'svm__gamma' : [0.1],\n",
    "                   'svm__kernel' : ['rbf']}\n",
    "\n",
    "search = GridSearchCV(svc, params_grid_svc, n_jobs=-1, cv=cv, verbose=0, scoring='accuracy')\n",
    "\n",
    "search.fit(X_train, y_train)\n",
    "\n",
    "y_pred = search.predict(X_test)\n",
    "\n",
    "print(f'\\nLe meilleur score entraînement est : {search.best_score_}\\n') # 0.9033\n",
    "print(f'\\nLe meilleur score test est : {search.score(X_test, y_test)}') # 0.9005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.92      0.98      0.95      7636\n",
      "         Yes       0.65      0.35      0.45      1030\n",
      "\n",
      "    accuracy                           0.90      8666\n",
      "   macro avg       0.79      0.66      0.70      8666\n",
      "weighted avg       0.89      0.90      0.89      8666\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true=y_test, y_pred=y_pred, target_names = ['No','Yes']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb = Pipeline(steps=[('preprocessor' , preprocessor),\n",
    "                      ('gnb', GaussianNB())])\n",
    "\n",
    "#gnb.get_params().keys()\n",
    "#search.best_params_\n",
    "\n",
    "params_grid_gnb = {'gnb' : [GaussianNB()],\n",
    "                   'gnb__priors' : [None],\n",
    "                   'gnb__var_smoothing' : [1e-08]}\n",
    "\n",
    "search = GridSearchCV(gnb, params_grid_gnb, n_jobs=-1, cv=cv, verbose=0, scoring='accuracy')\n",
    "\n",
    "search.fit(X_train, y_train)\n",
    "\n",
    "y_pred = search.predict(X_test)\n",
    "\n",
    "print(f'\\nLe meilleur score entraînement est : {search.best_score_}\\n') # 0.8350\n",
    "print(f'\\nLe meilleur score test est : {search.score(X_test, y_test)}') # 0.8262"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.92      0.88      0.90      7636\n",
      "         Yes       0.33      0.46      0.39      1030\n",
      "\n",
      "    accuracy                           0.83      8666\n",
      "   macro avg       0.63      0.67      0.64      8666\n",
      "weighted avg       0.85      0.83      0.84      8666\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true=y_test, y_pred=y_pred, target_names = ['No','Yes']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNeighbors Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "knc = Pipeline(steps=[('preprocessor' , preprocessor),\n",
    "                      ('knc', KNeighborsClassifier())])\n",
    "\n",
    "#knc.get_params().keys()\n",
    "#search.best_params_\n",
    "\n",
    "params_grid_knc = {'knc' : [KNeighborsClassifier()],\n",
    "                   'knc__n_neighbors': [5],\n",
    "                   'knc__leaf_size': [30],\n",
    "                   'knc__p': [1]}\n",
    "\n",
    "search = GridSearchCV(knc, params_grid_knc, n_jobs=-1, cv=cv, verbose=0, scoring='accuracy')\n",
    "\n",
    "search.fit(X_train, y_train)\n",
    "\n",
    "y_pred = search.predict(X_test)\n",
    "\n",
    "print(f'\\nLe meilleur score entraînement est : {search.best_score_}\\n') # 0.8893\n",
    "print(f'\\nLe meilleur score test est : {search.score(X_test, y_test)}') # 0.8922"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.91      0.98      0.94      7636\n",
      "         Yes       0.60      0.27      0.38      1030\n",
      "\n",
      "    accuracy                           0.89      8666\n",
      "   macro avg       0.76      0.63      0.66      8666\n",
      "weighted avg       0.87      0.89      0.87      8666\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true=y_test, y_pred=y_pred, target_names = ['No','Yes']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc = Pipeline(steps=[('preprocessor' , preprocessor),\n",
    "                      ('dtc', DecisionTreeClassifier())])\n",
    "\n",
    "#dtc.get_params().keys()\n",
    "#search.best_params_\n",
    "\n",
    "params_grid_dtc = {'dtc' : [DecisionTreeClassifier()],\n",
    "                   'dtc__criterion': [\"gini\"],\n",
    "                   'dtc__splitter': [\"best\"],\n",
    "                   'dtc__max_depth': [8],\n",
    "                   'dtc__min_samples_split': [2],\n",
    "                   'dtc__min_samples_leaf': [1]}\n",
    "\n",
    "search = GridSearchCV(dtc, params_grid_dtc, n_jobs=-1, cv=cv, verbose=0, scoring='accuracy')\n",
    "\n",
    "search.fit(X_train, y_train)\n",
    "\n",
    "y_pred = search.predict(X_test)\n",
    "\n",
    "print(f'\\nLe meilleur score entraînement est : {search.best_score_}\\n') # 0.9047\n",
    "print(f'\\nLe meilleur score test est : {search.score(X_test, y_test)}') # 0.9075"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.94      0.95      0.95      7636\n",
      "         Yes       0.62      0.56      0.59      1030\n",
      "\n",
      "    accuracy                           0.91      8666\n",
      "   macro avg       0.78      0.76      0.77      8666\n",
      "weighted avg       0.90      0.91      0.91      8666\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true=y_test, y_pred=y_pred, target_names = ['No','Yes']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomForest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = Pipeline(steps=[('preprocessor' , preprocessor),\n",
    "                      ('rf', RandomForestClassifier())])\n",
    "\n",
    "#rf.get_params().keys()\n",
    "#search.best_params_\n",
    "\n",
    "params_grid_rf = {'rf' : [RandomForestClassifier()],\n",
    "                  'rf__bootstrap': [True],\n",
    "                  'rf__max_features': ['auto'],\n",
    "                  'rf__n_estimators': [100],\n",
    "                  'rf__criterion': [\"gini\"],\n",
    "                  'rf__max_depth': [None],\n",
    "                  'rf__min_samples_split': [2],\n",
    "                  'rf__min_samples_leaf': [1]}\n",
    "\n",
    "search = GridSearchCV(rf, params_grid_rf, n_jobs=-1, cv=cv, verbose=0, scoring='accuracy')\n",
    "\n",
    "search.fit(X_train, y_train)\n",
    "\n",
    "y_pred = search.predict(X_test)\n",
    "\n",
    "print(f'\\nLe meilleur score entraînement est : {search.best_score_}\\n') # 0.9086 \n",
    "print(f'\\nLe meilleur score test est : {search.score(X_test, y_test)}') # 0.9111"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.93      0.97      0.95      7636\n",
      "         Yes       0.69      0.50      0.58      1030\n",
      "\n",
      "    accuracy                           0.91      8666\n",
      "   macro avg       0.81      0.73      0.76      8666\n",
      "weighted avg       0.91      0.91      0.91      8666\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true=y_test, y_pred=y_pred, target_names = ['No','Yes']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GradientBoosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbc = Pipeline(steps=[('preprocessor' , preprocessor),\n",
    "                      ('gbc', GradientBoostingClassifier())])\n",
    "\n",
    "#gbc.get_params().keys()\n",
    "#search.best_params_\n",
    "\n",
    "params_grid_gbc = {'gbc': [GradientBoostingClassifier()],\n",
    "                   'gbc__n_estimators': [100],\n",
    "                   'gbc__loss': ['deviance'],\n",
    "                   'gbc__learning_rate': [1],\n",
    "                   'gbc__max_depth': [1],\n",
    "                   'gbc__max_features' : ['sqrt'],\n",
    "                   'gbc__random_state': [10]}\n",
    "\n",
    "search = GridSearchCV(gbc, params_grid_gbc, n_jobs=-1, cv=cv, verbose=0, scoring='accuracy')\n",
    "\n",
    "search.fit(X_train, y_train)\n",
    "\n",
    "y_pred = search.predict(X_test)\n",
    "\n",
    "print(f'\\nLe meilleur score entraînement est : {search.best_score_}\\n') # 0.9058\n",
    "print(f'\\nLe meilleur score test est : {search.score(X_test, y_test)}') # 0.9081"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.93      0.97      0.95      7636\n",
      "         Yes       0.67      0.44      0.53      1030\n",
      "\n",
      "    accuracy                           0.91      8666\n",
      "   macro avg       0.80      0.71      0.74      8666\n",
      "weighted avg       0.90      0.91      0.90      8666\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true=y_test, y_pred=y_pred, target_names = ['No','Yes']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "abc = Pipeline(steps=[('preprocessor' , preprocessor),\n",
    "                      ('abc', AdaBoostClassifier())])\n",
    "\n",
    "#abc.get_params().keys()\n",
    "#search.best_params_\n",
    "\n",
    "params_grid_abc = {'abc': [AdaBoostClassifier()],\n",
    "                   'abc__n_estimators': [100],\n",
    "                   'abc__learning_rate': [1],\n",
    "                   'abc__random_state': [10]}\n",
    "\n",
    "search = GridSearchCV(abc, params_grid_abc, n_jobs=-1, cv=cv, verbose=0, scoring='accuracy')\n",
    "\n",
    "search.fit(X_train, y_train)\n",
    "\n",
    "y_pred = search.predict(X_test)\n",
    "\n",
    "print(f'\\nLe meilleur score entraînement est : {search.best_score_}\\n') # 0.9046\n",
    "print(f'\\nLe meilleur score test est : {search.score(X_test, y_test)}') # 0.9072"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.93      0.97      0.95      7636\n",
      "         Yes       0.68      0.42      0.52      1030\n",
      "\n",
      "    accuracy                           0.91      8666\n",
      "   macro avg       0.80      0.69      0.73      8666\n",
      "weighted avg       0.90      0.91      0.90      8666\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true=y_test, y_pred=y_pred, target_names = ['No','Yes']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "boost = Pipeline(steps=[('preprocessor' , preprocessor),\n",
    "                        ('xgb', XGBClassifier())])\n",
    "\n",
    "#boost.get_params().keys()\n",
    "#search.best_params_\n",
    "\n",
    "params_grid_xgb = {'xgb': [XGBClassifier()],\n",
    "                   'xgb__booster': ['gbtree'],\n",
    "                   'xgb__eta': [0.3],\n",
    "                   'xgb__gamma': [0],\n",
    "                   'xgb__max_depth': [6],\n",
    "                   'xgb__min_child_weight': [1],\n",
    "                   'xgb__max_delta_step': [0],\n",
    "                   'xgb__subsample': [1],\n",
    "                   'xgb__colsample_bytree': [1]}\n",
    "\n",
    "search = GridSearchCV(boost, params_grid_xgb, n_jobs=-1, cv=cv, verbose=0, scoring='accuracy')\n",
    "\n",
    "search.fit(X_train, y_train)\n",
    "\n",
    "y_pred = search.predict(X_test)\n",
    "\n",
    "print(f'\\nLe meilleur score entraînement est : {search.best_score_}\\n') # 0.9074\n",
    "print(f'\\nLe meilleur score test est : {search.score(X_test, y_test)}') # 0.9091"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.93      0.96      0.95      7636\n",
      "         Yes       0.65      0.50      0.57      1030\n",
      "\n",
      "    accuracy                           0.91      8666\n",
      "   macro avg       0.79      0.73      0.76      8666\n",
      "weighted avg       0.90      0.91      0.90      8666\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true=y_test, y_pred=y_pred, target_names = ['No','Yes']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightGBM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm = Pipeline(steps=[('preprocessor' , preprocessor),\n",
    "                        ('lgbm', LGBMClassifier())])\n",
    "\n",
    "#lgbm.get_params().keys()\n",
    "#search.best_params_\n",
    "\n",
    "params_grid_lgbm = {'lgbm': [LGBMClassifier()],\n",
    "                    'lgbm__boosting_type ': ['gbdt'],\n",
    "                    'lgbm__learning_rate ': [0.1],\n",
    "                    'lgbm__n_estimators': [100],\n",
    "                    'lgbm__max_depth': [1],\n",
    "                    'lgbm__min_child_weight': [1e-3],\n",
    "                    'lgbm__num_leaves': [31],\n",
    "                    'lgbm__min_split_gain': [0],\n",
    "                    'lgbm__colsample_bytree': [1]}\n",
    "\n",
    "search = GridSearchCV(lgbm, params_grid_lgbm, n_jobs=-1, cv=cv, verbose=0, scoring='accuracy')\n",
    "\n",
    "search.fit(X_train, y_train)\n",
    "\n",
    "y_pred = search.predict(X_test)\n",
    "\n",
    "print(f'\\nLe meilleur score entraînement est : {search.best_score_}\\n') # 0.90\n",
    "print(f'\\nLe meilleur score test est : {search.score(X_test, y_test)}') # 0.90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.91      0.99      0.95      7636\n",
      "         Yes       0.71      0.27      0.39      1030\n",
      "\n",
      "    accuracy                           0.90      8666\n",
      "   macro avg       0.81      0.63      0.67      8666\n",
      "weighted avg       0.89      0.90      0.88      8666\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true=y_test, y_pred=y_pred, target_names = ['No','Yes']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CatBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = Pipeline(steps=[('preprocessor' , preprocessor),\n",
    "                      ('cat', CatBoostClassifier())])\n",
    "\n",
    "#cat.get_params().keys()\n",
    "#search.best_params_\n",
    "\n",
    "params_grid_cat = {'cat': [CatBoostClassifier()]}\n",
    "\n",
    "search = GridSearchCV(cat, params_grid_cat, n_jobs=-1, cv=cv, verbose=0, scoring='accuracy')\n",
    "\n",
    "search.fit(X_train, y_train)\n",
    "\n",
    "y_pred = search.predict(X_test)\n",
    "\n",
    "print(f'\\nLe meilleur score entraînement est : {search.best_score_}\\n') # 0.9094\n",
    "print(f'\\nLe meilleur score test est : {search.score(X_test, y_test)}') # 0.9125"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.94      0.97      0.95      7636\n",
      "         Yes       0.67      0.52      0.59      1030\n",
      "\n",
      "    accuracy                           0.91      8666\n",
      "   macro avg       0.80      0.74      0.77      8666\n",
      "weighted avg       0.91      0.91      0.91      8666\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true=y_test, y_pred=y_pred, target_names = ['No','Yes']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_ps",
   "language": "python",
   "name": "ml_ps"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
