{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<36108x38 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 596142 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from product_sub.infrastructure.dataset_builder import DatasetBuilder\n",
    "from product_sub.domain.data_cleaning import NumImputer, CatImputer\n",
    "from product_sub.domain.feature_selector import FeatureSelector\n",
    "import product_sub.settings as stg\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import FeatureUnion, Pipeline, make_pipeline, make_union\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "dataset_merged = DatasetBuilder(\n",
    "    filename_bank=\"data.csv\", filename_socio=\"socio_eco.csv\"\n",
    ").merge()\n",
    "\n",
    "dataset_merged = dataset_merged.drop(columns=stg.COL_RAW_DATE)\n",
    "X = dataset_merged.drop(columns=stg.COL_RAW_SUBSCRIPTION)\n",
    "y = dataset_merged[stg.COL_RAW_SUBSCRIPTION].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "num_pipe = Pipeline(steps=[\n",
    "    ('feature_selector_num', FeatureSelector(np.number)),\n",
    "    ('num_imputer', NumImputer()),\n",
    "    ('scaler', StandardScaler())])\n",
    "cat_pipe = Pipeline(steps=[\n",
    "    ('feature_selector_cat', FeatureSelector(object)),\n",
    "    ('cat_imputer', CatImputer([stg.COL_RAW_JOB, stg.COL_RAW_EDUCATION]) ),\n",
    "    ('encoder', OneHotEncoder())\n",
    "])\n",
    "\n",
    "preprocess_pipeline = FeatureUnion(transformer_list=[\n",
    "        (\"numerical_pipeline\", num_pipe),\n",
    "        (\"categorical_pipeline\", cat_pipe),\n",
    "    ])\n",
    "\n",
    "X_train = preprocess_pipeline.fit_transform(X_train)\n",
    "X_train\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    " \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "\n",
    "dict_classifiers = {\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"Nearest Neighbors\": KNeighborsClassifier(),\n",
    "    \"Linear SVM\": SVC(),\n",
    "    \"Gradient Boosting Classifier\": GradientBoostingClassifier(),\n",
    "    \"Decision Tree\": tree.DecisionTreeClassifier(),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=18),\n",
    "    \"Neural Net\": MLPClassifier(alpha=1)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emiliodesousa/Documents/Yotta_Academy/Projets/Machine_Learning/productsubscription_eds_dm/.venv/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/emiliodesousa/Documents/Yotta_Academy/Projets/Machine_Learning/productsubscription_eds_dm/.venv/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/emiliodesousa/Documents/Yotta_Academy/Projets/Machine_Learning/productsubscription_eds_dm/.venv/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Logistic Regression\n",
    "log_reg = LogisticRegression()\n",
    "log_scores = cross_val_score(log_reg, X_train, y_train, cv=3)\n",
    "log_reg_mean = log_scores.mean()\n",
    "\n",
    "# SVC\n",
    "svc_clf = SVC()\n",
    "svc_scores = cross_val_score(svc_clf, X_train, y_train, cv=3)\n",
    "svc_mean = svc_scores.mean()\n",
    "\n",
    "# KNearestNeighbors\n",
    "knn_clf = KNeighborsClassifier()\n",
    "knn_scores = cross_val_score(knn_clf, X_train, y_train, cv=3)\n",
    "knn_mean = knn_scores.mean()\n",
    "\n",
    "# Decision Tree\n",
    "tree_clf = tree.DecisionTreeClassifier()\n",
    "tree_scores = cross_val_score(tree_clf, X_train, y_train, cv=3)\n",
    "tree_mean = tree_scores.mean()\n",
    "\n",
    "# Gradient Boosting Classifier\n",
    "grad_clf = GradientBoostingClassifier()\n",
    "grad_scores = cross_val_score(grad_clf, X_train, y_train, cv=3)\n",
    "grad_mean = grad_scores.mean()\n",
    "\n",
    "# Random Forest Classifier\n",
    "rand_clf = RandomForestClassifier(n_estimators=18)\n",
    "rand_scores = cross_val_score(rand_clf, X_train, y_train, cv=3)\n",
    "rand_mean = rand_scores.mean()\n",
    "\n",
    "# NeuralNet Classifier\n",
    "neural_clf = MLPClassifier(alpha=1)\n",
    "neural_scores = cross_val_score(neural_clf, X_train, y_train, cv=3)\n",
    "neural_mean = neural_scores.mean()\n",
    "\n",
    "\n",
    "d = {'Classifiers': ['Logistic Reg.', 'SVC', 'KNN', 'Dec Tree', 'Grad B CLF', 'Rand FC', 'Neural Classifier'], \n",
    "    'Crossval Mean Scores': [log_reg_mean, svc_mean, knn_mean, tree_mean, grad_mean, rand_mean, neural_mean]}\n",
    "\n",
    "result_df = pd.DataFrame(data=d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifiers</th>\n",
       "      <th>Crossval Mean Scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Reg.</td>\n",
       "      <td>0.905561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.905201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.895369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dec Tree</td>\n",
       "      <td>0.877645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Grad B CLF</td>\n",
       "      <td>0.909134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Rand FC</td>\n",
       "      <td>0.902819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Neural Classifier</td>\n",
       "      <td>0.906807</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Classifiers  Crossval Mean Scores\n",
       "0      Logistic Reg.              0.905561\n",
       "1                SVC              0.905201\n",
       "2                KNN              0.895369\n",
       "3           Dec Tree              0.877645\n",
       "4         Grad B CLF              0.909134\n",
       "5            Rand FC              0.902819\n",
       "6  Neural Classifier              0.906807"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'xgboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-e6b2443346ed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mxgboost\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'xgboost'"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_project_1",
   "language": "python",
   "name": "env_project_1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
